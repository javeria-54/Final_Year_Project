| **Architecture**                             | **Execution Timing / Speed**                                                                               | **Functional Units**                                                            | **SEW (Element Width) Handling**                | **Documentation & Maturity**                          | **Key Limitations**                                                    |
| -------------------------------------------- | ---------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------- | ----------------------------------------------- | ----------------------------------------------------- | ---------------------------------------------------------------------- |
| **Cray-1** (1976)                            | Fully pipelined — each vector operation overlapped; fixed latency per pipeline (e.g., 12 cycles for add).  | Separate vector pipelines for Add, Multiply, Logical; scalar unit for control.  | Fixed 64-bit only.                              | Well-documented (historical reference in HPC design). | No support for variable precision; poor utilization for short vectors. |
| **NEC SX-Aurora Tsubasa** (2018)             | High throughput for long vectors (>256 elements); pipeline depth ~16–20 stages.                            | Dedicated vector ALUs (add/mul/div), load/store units, vector registers.        | Fixed 64-bit precision; no SEW reconfiguration. | Detailed vendor docs but proprietary.                 | Long pipeline latency; limited flexibility.                            |
| **Fujitsu A64FX (ARM SVE)** (2019)           | Execution time depends on SEW; smaller SEW reduces per-cycle throughput (control overhead).                | 8 lanes × 128-bit, each with ALU + FMA; masked predication unit.                | Dynamic SEW (8/16/32/64 bits).                  | Excellent official ARM SVE ISA docs.                  | Complex decode; performance drops for small SEW.                       |
| **Intel Xeon Phi (Knights Landing)** (2016)  | Up to 2 vector instructions per cycle (512-bit); speed degrades when mixing SEWs.                          | AVX-512 vector units (8 × 64-bit lanes) + scalar core.                          | SEW: 8/16/32/64-bit via AVX-512.                | Fully open documentation (Intel Developer Manual).    | High power; thermal throttling during wide operations.                 |
| **RISC-V Vector (RVV)** (2021–present)       | Variable execution time — depends on vector length (VL) and SEW; VL/SEW reconfiguration stalls 2–3 cycles. | Independent ALUs, multipliers, mask & memory units; pipeline control via vtype. | Fully programmable SEW/LMUL (8–64 bits).        | Open-source specification (v1.0 ratified).            | Complex control for dynamic SEW; incomplete HW adoption.               |
| **TI C66x DSP** (2013)                       | Executes 8 × 16-bit MACs per cycle (SIMD); slower for 32/64-bit ops.                                       | 8 ALUs + 2 multipliers; divided into clusters.                                  | Fixed SIMD width (16–64-bit).                   | Detailed TI documentation.                            | Static width; not true vector (SIMD).                                  |
| **NVIDIA CUDA Vector Cores** (for reference) | Very high throughput via SIMT scheduling; latency hidden by thread-level parallelism.                      | Scalar pipelines grouped in warps; vectorization handled in software.           | No SEW concept (handled by compiler).           | Excellent developer docs (CUDA Toolkit).              | Control-heavy; not true hardware vectorization.                        |
